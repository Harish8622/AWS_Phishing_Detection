{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf530938-e691-4140-8028-0d9aad14e88e",
   "metadata": {},
   "source": [
    "# Training Notebook 2\n",
    "## Dropping Non-Important Features\n",
    "\n",
    "Based on feature importance analysis, we identified the following features as having zero importance:\n",
    "\n",
    "- `IsDomainIP` (Index 3)\n",
    "- `NoOfEqualsInURL` (Index 6)\n",
    "- `NoOfQMarkInURL` (Index 7)\n",
    "- `URLEntropy` (Index 12)\n",
    "\n",
    "Since the dataset has no headers, we use these indices to drop the columns directly. This ensures that the final dataset is smaller, more efficient, and contains only the features that actually contribute to the modelâ€™s predictions.\n",
    "\n",
    "The remaining columns are:\n",
    "\n",
    "- `label`\n",
    "- `URLLength`\n",
    "- `DomainLength`\n",
    "- `NoOfSubDomain`\n",
    "- `LetterRatioInURL`\n",
    "- `NoOfAmpersandInURL`\n",
    "- `SpacialCharRatioInURL`\n",
    "- `IsHTTPS`\n",
    "- `CharContinuationRate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83298e-d299-49e8-a1cb-eab3c9e3df07",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309d7b1-e785-4abb-8b60-d282b6d2f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# AWS and SageMaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Session, get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker import image_uris\n",
    "\n",
    "# Machine learning and evaluation\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6b732-7315-482a-875a-7ab4e4071aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "input_dir = '../data/initial_processed_data'\n",
    "output_dir = '../data/data_reduced_features'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Columns to drop (indices of the features to remove)\n",
    "columns_to_drop = [3,6,7,12]\n",
    "\n",
    "# Files to process\n",
    "files = ['train.csv', 'validation.csv', 'test.csv']\n",
    "\n",
    "for file in files:\n",
    "    input_path = os.path.join(input_dir, file)\n",
    "    output_path = os.path.join(output_dir, file)\n",
    "    \n",
    "    # Read CSV without headers\n",
    "    df = pd.read_csv(input_path, header=None)\n",
    "    \n",
    "    # Drop the specified columns\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Save the cleaned dataset\n",
    "    df_cleaned.to_csv(output_path, index=False, header=False)\n",
    "    print(f\"Processed and saved {file} -> {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f83812-dd1f-4da0-bb86-3d6afadde183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 config\n",
    "bucket = 'bucket_name'\n",
    "s3_prefix = 'data/data_reduced_features'\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Upload files\n",
    "for file in files:\n",
    "    local_path = os.path.join(output_dir, file)\n",
    "    s3_key = f\"{s3_prefix}/{file}\"\n",
    "    \n",
    "    s3.upload_file(local_path, bucket, s3_key)\n",
    "    print(f\"Uploaded {file} to s3://{bucket}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc38692-8469-42a2-bb22-445a992f4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "\n",
    "# Paths\n",
    "original_path = '../data/initial_processed_data/train.csv'\n",
    "cleaned_path = '../data/data_reduced_features/train.csv'\n",
    "\n",
    "# Load datasets (no headers!)\n",
    "df_original = pd.read_csv(original_path, header=None)\n",
    "df_cleaned = pd.read_csv(cleaned_path, header=None)\n",
    "\n",
    "# Show head of original dataset\n",
    "print(\"\\n===== Original Dataset Head (first 5 rows) =====\")\n",
    "print(df_original.head())\n",
    "\n",
    "# Show head of cleaned dataset\n",
    "print(\"\\n===== Cleaned Dataset Head (first 5 rows) =====\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Show mapping of original to cleaned (skipping dropped columns)\n",
    "original_cols_to_keep = [0, 1, 2, 4, 5, 8, 9, 10, 11]\n",
    "print(\"\\n===== Original Columns Kept Indices =====\")\n",
    "print(original_cols_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20d3ce-9931-482c-b8fa-9f8c37d722f0",
   "metadata": {},
   "source": [
    "# Retrain with the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08628e-ba6d-48ff-b0d4-9d71fca08b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = Session()\n",
    "region = session.boto_region_name\n",
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"300\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = 'bucket_name'\n",
    "s3_output_key = 'models/xgboost/v2'\n",
    "output_path = f's3://{bucket}/{s3_output_key}'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "# construct a SageMaker AI estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=role,\n",
    "                                          instance_count=2, # demonstrating multi instance training\n",
    "                                          instance_type='ml.m5.large', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef83bc-5711-4da8-80a0-d712dbd61414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "bucket = 'bucket_name'\n",
    "prefix = 'data/data_reduced_features'\n",
    "\n",
    "train_input = TrainingInput(f\"s3://{bucket}/{prefix}/train.csv\", content_type=content_type)\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/{prefix}/validation.csv\", content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af160f3b-6ca9-4a3f-8cf9-af502faf1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect path\n",
    "f\"s3://{bucket}/{prefix}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3119094-b892-4c0e-8404-71c04322a469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit({'train': train_input, 'validation': validation_input}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba7b44-45f2-4d83-be31-7df166750e28",
   "metadata": {},
   "source": [
    "model data saved to `path_to_model_tar`\n",
    "\n",
    "# Test XGBOOST Model\n",
    "- need metrics to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc7be4-fe03-4350-a0ad-ff19f4270ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'bucket_name'\n",
    "prefix = 'data/data_reduced_features/test.csv'\n",
    "local_file = '../data/local_test_data/test_v2.csv'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, prefix, local_file)\n",
    "print(f\"Downloaded {prefix} from S3 to {local_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0bf6d-807a-4436-9856-177fb1cc3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV (no header, label is first column)\n",
    "df_test = pd.read_csv(local_file, header=None)\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d137cab-e107-46f4-9387-65b7e04e6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model location in S3\n",
    "bucket = 'bucket_name'\n",
    "model_key = 'models/xgboost/v2/sagemaker-xgboost-2025-06-03-14-53-12-660/output/model.tar.gz'\n",
    "local_file = '../data/local_model_data/xgboost-v2/model.tar.gz'\n",
    "\n",
    "# Download model file\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, model_key, local_file)\n",
    "print(f\"Downloaded {model_key} from S3 to {local_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be3b306-1f76-46f9-85d2-d37450d58e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your desired target directory\n",
    "target_dir = \"../data/local_model_data/xgboost-v2/\"\n",
    "\n",
    "with tarfile.open(local_file) as tar:\n",
    "    tar.extractall(path=target_dir)\n",
    "\n",
    "print(f\"Model extracted to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e22ad-3ada-4800-8b7c-52393c8629d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.Booster()\n",
    "booster.load_model('../data/local_model_data/xgboost-v2/xgboost-model')  # built-in XGBoost saves as this name\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132b92d-048c-4c1e-9ae5-c941b2fb0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test data\n",
    "y_test = df_test.iloc[:, 0].astype(int)  # first column = label\n",
    "X_test = df_test.iloc[:, 1:]             # rest = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f50d6-412f-4f2f-a934-147de38fada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_prob = booster.predict(dtest)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7baeb-1b81-41a8-8c02-f92dc9f37e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Classification Report\n",
    "print(\"\\n===== Classification Report =====\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Accuracy\n",
    "print(\"\\n===== Accuracy Score =====\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81382d3b-d7cd-4d36-bc64-763c16672b46",
   "metadata": {},
   "source": [
    "# Deploy Endpoint\n",
    "- can continue to deployment from here no need to retrain if model is already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c202fa-fce9-4a19-928f-0d713e2bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SageMaker session and role\n",
    "role = get_execution_role()\n",
    "session = Session()\n",
    "region = session.boto_region_name\n",
    "\n",
    "# Path to the model artifact\n",
    "model_data = 'path_to_model_tar'\n",
    "\n",
    "# Create the Model object using SageMaker's built-in XGBoost image\n",
    "xgboost_image_uri = sagemaker.image_uris.retrieve('xgboost', region, version='1.7-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1693f-f52d-492b-abdb-2f0fadce6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=xgboost_image_uri,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cba87f-ecaf-4c3a-b3b3-8ced2c30f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model as an endpoint\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large', \n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(\"Endpoint deployed and ready for real-time inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ac3be-f01f-4a35-b404-1a9d0483522f",
   "metadata": {},
   "source": [
    "## Endpoint Deployed\n",
    "- Now create the lambda function using the code in `lambda_functions/lambda_functions.py`\n",
    "- Follow instructions in `README` to do this and test it and finally to create the API and Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c80ce9-cc0c-4e05-b36d-b2a91fca28cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
