{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f694330-421f-4855-acb4-4f2819f46054",
   "metadata": {},
   "source": [
    "# Training Notebook 1\n",
    "- in this notebook the first iteration of the xgboost model will be trained and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e66467-5e36-4365-a96c-f6fbb80a3dc5",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6303a2-5dc7-491b-827c-5091ec82c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS & SageMaker\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Session, get_execution_role, image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# Data handling & processing\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "\n",
    "# Model training & evaluation\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Visualisation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3442f1b-f0a4-42ec-89c6-2f8f18d0bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "session = Session()\n",
    "region = session.boto_region_name\n",
    "\n",
    "# initialise hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":\"300\"}\n",
    "\n",
    "# set an output path where the trained model will be saved\n",
    "bucket = 'bucket_name'\n",
    "s3_output_key = 'models/xgboost/v1'\n",
    "output_path = f's3://{bucket}/{s3_output_key}'\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "# construct a SageMaker  estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=role,\n",
    "                                          instance_count=2, # demonstrating multi instance training\n",
    "                                          instance_type='ml.m5.large', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f476e4-7a8d-4e64-a1d4-6eeec98661da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "bucket = 'bucket_name'\n",
    "prefix = 'data/initial_processed_data'\n",
    "\n",
    "train_input = TrainingInput(f\"s3://{bucket}/{prefix}/train.csv\", content_type=content_type)\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/{prefix}/validation.csv\", content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209df82-2710-41a5-9bdd-e501092c5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"s3://{bucket}/{prefix}/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dd641-3e48-43df-992c-14b1383fadfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input}, wait=True, logs=\"All\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c9a34-0460-48a6-8d77-c8cb3ac0eae9",
   "metadata": {},
   "source": [
    "model data saved to `s3://sagemaker-eu-west-1-277841471265/models/xgboost/v1/sagemaker-xgboost-2025-06-03-14-33-29-138/output/model.tar.gz`\n",
    "\n",
    "# Test XGBOOST Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab5e9c-01ae-4d9f-92c1-ec2261542fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test data locally\n",
    "bucket = 'bucket_name'\n",
    "prefix = 'data/initial_processed_data/test.csv'\n",
    "local_file = '../data/local_test_data/test.csv'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, prefix, local_file)\n",
    "print(f\"Downloaded {prefix} from S3 to {local_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79f7e8-1668-4db4-ac24-72200bf90b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open test data\n",
    "df_test = pd.read_csv(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc920b-e3f1-4f00-aba4-53e29f508cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and train\n",
    "y_test = df_test.iloc[:, 0].astype(int)  # first column = label\n",
    "X_test = df_test.iloc[:, 1:]             # rest = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744b67d-2b7c-44e9-8724-cfe770bba2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model\n",
    "bucket = 'bucket_name'\n",
    "model_key = 'models/xgboost/v1/sagemaker-xgboost-2025-06-03-14-33-29-138/output/model.tar.gz'\n",
    "local_file = '../data/local_model_data/xgboost-v1/model.tar.gz'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, model_key, local_file)\n",
    "print(f\"Downloaded {model_key} from S3 to {local_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b3fec-e6cd-477f-92f7-2908cfc5b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your desired target directory\n",
    "target_dir = \"../data/local_model_data/xgboost-v1/\"\n",
    "\n",
    "with tarfile.open(local_file) as tar:\n",
    "    tar.extractall(path=target_dir)\n",
    "\n",
    "print(f\"Model extracted to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66281bdf-50c1-4f6f-b02c-c5d11ddb054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "booster = xgb.Booster()\n",
    "booster.load_model('../data/local_model_data/xgboost-v1/xgboost-model')  # built-in XGBoost saves as this name\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb9179-22e9-49ea-8764-4d1b492587e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_prob = booster.predict(dtest)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48250a49-3f68-45ec-b6a5-836a86712930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Classification Report\n",
    "print(\"\\n===== Classification Report =====\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print Accuracy\n",
    "print(\"\\n===== Accuracy Score =====\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"\\n===== Confusion Matrix =====\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58047b05-36ca-4f66-a878-e7421acda4e3",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "- We will explore which features were the most important in the model\n",
    "- this can help to remove features not contributing, reducing the feature engineering requirement and the pre processing required at inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4f9494-576b-493b-9ff6-0e8de5d6e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importance as a list\n",
    "importance_dict = booster.get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60ff22-b8fb-480d-bbad-a4161b5b2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f7298-7ca6-4404-b747-8ff6536bb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature name list for mapping\n",
    "feature_names = [\n",
    "    'URLLength', 'DomainLength', 'IsDomainIP', 'NoOfSubDomain', 'LetterRatioInURL',\n",
    "    'NoOfEqualsInURL', 'NoOfQMarkInURL', 'NoOfAmpersandInURL',\n",
    "    'SpacialCharRatioInURL', 'IsHTTPS', 'CharContinuationRate', 'URLEntropy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca0308-c48b-42b1-8d7c-dc41e77f7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': [feature_names[int(k[1:])] for k in importance_dict.keys()],\n",
    "    'Importance': list(importance_dict.values())\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b593f04-4a4d-4fd5-93e6-441bd55d9f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance (Weight)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb065a-1bd5-4ced-9d3f-2fcb14e49ba8",
   "metadata": {},
   "source": [
    "### We will drop features not present here, as they did not contribute to the model\n",
    "These features are: \n",
    "- f3: IsDomainIP\n",
    "- f6: NoOfEqualsInURL\n",
    "- f7: NoOfQMarkInURL\n",
    "- f12: URLEntropy\n",
    "\n",
    "# We will continue in `training_notebook_2`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
